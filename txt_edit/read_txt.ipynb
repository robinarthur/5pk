{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import os.path\n",
    "import glob\n",
    "from chardet.universaldetector import UniversalDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzip(source_filename, dest_dir):\n",
    "    \"\"\"this function unzips all the files from the epub file\n",
    "        the following functions should only need the textfiles\"\"\"\n",
    "    with zipfile.ZipFile(source_filename) as zf:\n",
    "        for member in zf.infolist():\n",
    "            # Path traversal defense copied from\n",
    "            # http://hg.python.org/cpython/file/tip/Lib/http/server.py#l789\n",
    "            words = member.filename.split('/')\n",
    "            path = dest_dir\n",
    "            for word in words[:-1]:\n",
    "                while True:\n",
    "                    drive, word = os.path.splitdrive(word)\n",
    "                    head, word = os.path.split(word)\n",
    "                    if not drive:\n",
    "                        print(\"no drive\")\n",
    "                        break\n",
    "                if word in (os.curdir, os.pardir, ''):\n",
    "                    continue\n",
    "                path = os.path.join(path, word)\n",
    "            zf.extract(member, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_txt(dir):\n",
    "    for path in glob.glob(dir + '/*.html'):\n",
    "        with open(path) as markup:\n",
    "            soup = BeautifulSoup(markup.read(),\"html5lib\" )\n",
    "        with open(\"strip_\" + path, \"w\") as f:\n",
    "            f.write(soup.get_text().encode('ISO-8859-2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect(file):\n",
    "    detector = UniversalDetector()\n",
    "    for filename in glob.glob(file):\n",
    "        print(filename.ljust(60),detector.reset())\n",
    "        for line in file(filename, 'rb'):\n",
    "            detector.feed(line)\n",
    "            if detector.done:\n",
    "                break\n",
    "    \n",
    "    detector.close()\n",
    "    print(detector.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'schiller.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e7690d334923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"schiller.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"html5lib\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ISO-8859-2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'schiller.txt'"
     ]
    }
   ],
   "source": [
    "def convert(file, coding):\n",
    "    f = open(file)\n",
    "    \n",
    "    \n",
    "    \n",
    "f = open(\"schiller.txt\")\n",
    "soup = BeautifulSoup(f.read(),\"html5lib\" )\n",
    "g = soup.get_text().encode('ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fa65ea9164b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#nltk.download('stopwords')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#!pip3 install -U spacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# coding: latin1\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#!pip3 install -U spacy\n",
    "#!python -m spacy download de\n",
    "#import spacy\n",
    "import codecs\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlite3 import Error\n",
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "corpus_root = '/home/user/Dokumente/Github/5pk/txt_edit'\n",
    "\n",
    "\n",
    "# The books are splitted into several files. First i have to group the \n",
    "# files for every book and put them into one textstring\n",
    "\n",
    "# html_folder\n",
    "loc = \"/html\"\n",
    "\n",
    "##############################################\n",
    "#\n",
    "# 1. Teil vom input - bereits eingelesen\n",
    "#\n",
    "##############################################\n",
    "\n",
    "\n",
    "\n",
    "#book1 - Demetrius\n",
    "raw_book_1_1 = loc + '/' + 'Demetrius.html'\n",
    "raw_book_1 = [raw_book_1_1]\n",
    "\n",
    "#book2 - Der versöhnte Menschenfeind\n",
    "raw_book_2_1 = loc + '/' + 'DerVers_0.html'\n",
    "raw_book_2_2 = loc + '/' + 'DerVers_1.html'\n",
    "raw_book_2 = [raw_book_2_1, raw_book_2_2]\n",
    "\n",
    "#book3 - Die Braut von Messina\n",
    "raw_book_3_1 = loc + '/' + 'DieBraut_0.html'\n",
    "raw_book_3_2 = loc + '/' + 'DieBraut_1.html'\n",
    "raw_book_3_3 = loc + '/' + 'DieBraut_2.html'\n",
    "raw_book_3_4 = loc + '/' + 'DieBraut_3.html'\n",
    "raw_book_3_5 = loc + '/' + 'DieBraut_4.html'\n",
    "raw_book_3_6 = loc + '/' + 'DieBraut_5.html'\n",
    "raw_book_3_7 = loc + '/' + 'DieBraut_6.html'\n",
    "raw_book_3 = [raw_book_3_1, raw_book_3_2, raw_book_3_3, raw_book_3_4, \n",
    "              raw_book_3_5, raw_book_3_6, raw_book_3_7\n",
    "             ]\n",
    "\n",
    "#book4 - Die Huldigung der Künste - 1 - DieHuldi.html\n",
    "raw_book_4_1 = loc + '/' + 'DieHuldi.html'\n",
    "raw_book_4 = [raw_book_4_1]\n",
    "\n",
    "#book5 - Die Jungfrau von Orleans - 10 - DieJungfrau_00.html\n",
    "raw_book_5_1 = loc + '/' + 'DieJungfrau_00.html'\n",
    "raw_book_5_2 = loc + '/' + 'DieJungfrau_01.html'\n",
    "raw_book_5_3 = loc + '/' + 'DieJungfrau_02.html'\n",
    "raw_book_5_4 = loc + '/' + 'DieJungfrau_03.html'\n",
    "raw_book_5_5 = loc + '/' + 'DieJungfrau_04.html'\n",
    "raw_book_5_6 = loc + '/' + 'DieJungfrau_05.html'\n",
    "raw_book_5_7 = loc + '/' + 'DieJungfrau_06.html'\n",
    "raw_book_5_8 = loc + '/' + 'DieJungfrau_07.html'\n",
    "raw_book_5_9 = loc + '/' + 'DieJungfrau_08.html'\n",
    "raw_book_5_10 = loc + '/' + 'DieJungfrau_09.html'\n",
    "raw_book_5 = [raw_book_5_1, raw_book_5_2, raw_book_5_3, raw_book_5_4,\n",
    "              raw_book_5_5, raw_book_5_6, raw_book_5_7, raw_book_5_8,\n",
    "              raw_book_5_9, raw_book_5_10]\n",
    "\n",
    "#book6 - Die Räuber - 9 - DieRauber_0.html\n",
    "raw_book_6_1 = loc + '/' + 'DieRauber_0.html'\n",
    "raw_book_6_2 = loc + '/' + 'DieRauber_1.html'\n",
    "raw_book_6_3 = loc + '/' + 'DieRauber_2.html'\n",
    "raw_book_6_4 = loc + '/' + 'DieRauber_3.html'\n",
    "raw_book_6_5 = loc + '/' + 'DieRauber_4.html'\n",
    "raw_book_6_6 = loc + '/' + 'DieRauber_5.html'\n",
    "raw_book_6_7 = loc + '/' + 'DieRauber_6.html'\n",
    "raw_book_6_8 = loc + '/' + 'DieRauber_7.html'\n",
    "raw_book_6_9 = loc + '/' + 'DieRauber_8.html'\n",
    "raw_book_6 = [raw_book_6_1, raw_book_6_2, raw_book_6_3, raw_book_6_4,\n",
    "              raw_book_6_5, raw_book_6_6, raw_book_6_7, raw_book_6_8,\n",
    "              raw_book_6_9]\n",
    "\n",
    "#book7 - Die Verschwörung des fiesco zu Genua 13 - DieVersch_00.html\n",
    "raw_book_7_1 = loc + '/' + 'DieVersch_00.html'\n",
    "raw_book_7_2 = loc + '/' + 'DieVersch_01.html'\n",
    "raw_book_7_3 = loc + '/' + 'DieVersch_02.html'\n",
    "raw_book_7_4 = loc + '/' + 'DieVersch_03.html'\n",
    "raw_book_7_5 = loc + '/' + 'DieVersch_04.html'\n",
    "raw_book_7_6 = loc + '/' + 'DieVersch_05.html'\n",
    "raw_book_7_7 = loc + '/' + 'DieVersch_06.html'\n",
    "raw_book_7_8 = loc + '/' + 'DieVersch_07.html'\n",
    "raw_book_7_9 = loc + '/' + 'DieVersch_08.html'\n",
    "raw_book_7_10 = loc + '/' + 'DieVersch_09.html'\n",
    "raw_book_7_11 = loc + '/' + 'DieVersch_10.html'\n",
    "raw_book_7_12 = loc + '/' + 'DieVersch_11.html'\n",
    "raw_book_7_13 = loc + '/' + 'DieVersch_12.html'\n",
    "raw_book_7 = [raw_book_7_1, raw_book_7_2, raw_book_7_3, raw_book_7_4,\n",
    "              raw_book_7_5, raw_book_7_6, raw_book_7_7, raw_book_7_8,\n",
    "              raw_book_7_9, raw_book_7_10, raw_book_7_11, raw_book_7_12,\n",
    "              raw_book_7_13]\n",
    "\n",
    "#book8 - Don Carlos - 10 - DonCarlos_0.html\n",
    "raw_book_8_1 = loc + '/' + 'DonCarlos_0.html'\n",
    "raw_book_8_2 = loc + '/' + 'DonCarlos_1.html'\n",
    "raw_book_8_3 = loc + '/' + 'DonCarlos_2.html'\n",
    "raw_book_8_4 = loc + '/' + 'DonCarlos_3.html'\n",
    "raw_book_8_5 = loc + '/' + 'DonCarlos_4.html'\n",
    "raw_book_8_6 = loc + '/' + 'DonCarlos_5.html'\n",
    "raw_book_8_7 = loc + '/' + 'DonCarlos_6.html'\n",
    "raw_book_8_8 = loc + '/' + 'DonCarlos_7.html'\n",
    "raw_book_8_9 = loc + '/' + 'DonCarlos_8.html'\n",
    "raw_book_8_10 = loc + '/' + 'DonCarlos_9.html'\n",
    "raw_book_8 = [raw_book_8_1, raw_book_8_2, raw_book_8_3, raw_book_8_4,\n",
    "              raw_book_8_5, raw_book_8_6, raw_book_8_7, raw_book_8_8,\n",
    "              raw_book_8_9]\n",
    "\n",
    "#book9 - Kabale und Liebe 7 - KabaleUnd_0.html\n",
    "raw_book_9_1 = loc + '/' + 'KabaleUnd_0.html'\n",
    "raw_book_9_2 = loc + '/' + 'KabaleUnd_1.html'\n",
    "raw_book_9_3 = loc + '/' + 'KabaleUnd_2.html'\n",
    "raw_book_9_4 = loc + '/' + 'KabaleUnd_3.html'\n",
    "raw_book_9_5 = loc + '/' + 'KabaleUnd_4.html'\n",
    "raw_book_9_6 = loc + '/' + 'KabaleUnd_5.html'\n",
    "raw_book_9_7 = loc + '/' + 'KabaleUnd_6.html'\n",
    "raw_book_9 = [raw_book_9_1, raw_book_9_2, raw_book_9_3, raw_book_9_4,\n",
    "              raw_book_9_5, raw_book_9_6, raw_book_9_7]\n",
    "\n",
    "#book10- Maria Stuart - 7 - MariaStuart_0.html\n",
    "raw_book_10_1 = loc + '/' + 'MariaStuart_0.html'\n",
    "raw_book_10_2 = loc + '/' + 'MariaStuart_1.html'\n",
    "raw_book_10_3 = loc + '/' + 'MariaStuart_2.html'\n",
    "raw_book_10_4 = loc + '/' + 'MariaStuart_3.html'\n",
    "raw_book_10_5 = loc + '/' + 'MariaStuart_4.html'\n",
    "raw_book_10_6 = loc + '/' + 'MariaStuart_5.html'\n",
    "raw_book_10_7 = loc + '/' + 'MariaStuart_6.html'\n",
    "raw_book_10 = [raw_book_10_1, raw_book_10_2, raw_book_10_3, raw_book_10_4,\n",
    "               raw_book_10_5, raw_book_10_6, raw_book_10_7]\n",
    "\n",
    "#book11- Semele\n",
    "raw_book_11_1 = loc + '/' + 'Semele_0.html'\n",
    "raw_book_11_2 = loc + '/' + 'Semele_1.html'\n",
    "raw_book_11_3 = loc + '/' + 'Semele_2.html'\n",
    "raw_book_11 = [raw_book_11_1, raw_book_11_2, raw_book_11_3]\n",
    "\n",
    "#book12- Wallenstein\n",
    "raw_book_12_1 = loc + '/' + 'Wallenstein_0.html'\n",
    "raw_book_12_2 = loc + '/' + 'Wallenstein_1.html'\n",
    "raw_book_12_3 = loc + '/' + 'Wallenstein_2.html'\n",
    "raw_book_12_4 = loc + '/' + 'Wallenstein_3.html'\n",
    "raw_book_12_5 = loc + '/' + 'Wallenstein_4.html'\n",
    "raw_book_12_6 = loc + '/' + 'Wallenstein_5.html'\n",
    "raw_book_12_7 = loc + '/' + 'Wallenstein_6.html'\n",
    "raw_book_12_8 = loc + '/' + 'Wallenstein_7.html'\n",
    "raw_book_12_9 = loc + '/' + 'Wallenstein_8.html'\n",
    "raw_book_12_10 = loc + '/' + 'Wallenstein_9.html'\n",
    "raw_book_12_11 = loc + '/' + 'Wallenstein_10.html'\n",
    "raw_book_12_12 = loc + '/' + 'Wallenstein_11.html'\n",
    "raw_book_12_13 = loc + '/' + 'Wallenstein_12.html'\n",
    "raw_book_12_14 = loc + '/' + 'Wallenstein_13.html'\n",
    "raw_book_12_15 = loc + '/' + 'Wallenstein_14.html'\n",
    "raw_book_12_16 = loc + '/' + 'Wallenstein_15.html'\n",
    "raw_book_12_17 = loc + '/' + 'Wallenstein_16.html'\n",
    "raw_book_12_18 = loc + '/' + 'Wallenstein_17.html'\n",
    "raw_book_12_19 = loc + '/' + 'Wallenstein_18.html'\n",
    "raw_book_12_20 = loc + '/' + 'Wallenstein_19.html'\n",
    "raw_book_12_21 = loc + '/' + 'Wallenstein_20.html'\n",
    "raw_book_12 = [raw_book_12_1, raw_book_12_2, raw_book_12_3, raw_book_12_4,\n",
    "               raw_book_12_5, raw_book_12_6, raw_book_12_7, raw_book_12_8,\n",
    "               raw_book_12_9, raw_book_12_10, raw_book_12_11, raw_book_12_12,\n",
    "               raw_book_12_13, raw_book_12_14, raw_book_12_15, raw_book_12_16,\n",
    "               raw_book_12_17, raw_book_12_18, raw_book_12_19, raw_book_12_20,\n",
    "               raw_book_12_21\n",
    "              ]\n",
    "\n",
    "#book13- Wilhelm Tell\n",
    "raw_book_13_1 = loc + '/' + 'WilhelmTell_0.html'\n",
    "raw_book_13_2 = loc + '/' + 'WilhelmTell_1.html'\n",
    "raw_book_13_3 = loc + '/' + 'WilhelmTell_3.html'\n",
    "raw_book_13_4 = loc + '/' + 'WilhelmTell_4.html'\n",
    "raw_book_13_5 = loc + '/' + 'WilhelmTell_5.html'\n",
    "raw_book_13_6 = loc + '/' + 'WilhelmTell_6.html'\n",
    "raw_book_13_7 = loc + '/' + 'WilhelmTell_7.html'\n",
    "raw_book_13 = [raw_book_13_1, raw_book_13_2, raw_book_13_3, raw_book_13_4,\n",
    "               raw_book_13_5, raw_book_13_6, raw_book_13_7\n",
    "              ]\n",
    "\n",
    "##############################################\n",
    "#\n",
    "# 1. Teil des inputs ist beendet\n",
    "#\n",
    "##############################################\n",
    "\n",
    "\n",
    "raw_books_schiller = [(raw_book_1,1),\n",
    "                      (raw_book_2,2),\n",
    "                      (raw_book_3,7),\n",
    "                      (raw_book_4,1),\n",
    "                      (raw_book_5,10),\n",
    "                      (raw_book_6,9),\n",
    "                      (raw_book_7,13),\n",
    "                      (raw_book_8,9),\n",
    "                      (raw_book_9,7),\n",
    "                      (raw_book_10,7),\n",
    "                      (raw_book_11,3),\n",
    "                      (raw_book_12,21),\n",
    "                      (raw_book_13,7)\n",
    "                     ]\n",
    "\n",
    "print(type(raw_books_schiller))\n",
    "\n",
    "\n",
    "# NLTK's default German stopwords\n",
    "default_stopwords = set(nltk.corpus.stopwords.words('german'))\n",
    "custom_stopwords = set((u'–', u'dass', u'mehr', u'0000ff', u'000ff', u'0em', u'1.2', u'1em', u'2em', u'a.sgc-2',\n",
    "                        u'center', u'color', u'div.sgc-1', u'div.sgc-5', u'div.sgc-toc-level-1',\n",
    "                        u'div.sgc-toc-level-2', u'div.sgc-toc-level-3', u'div.sgc-toc-level-4',\n",
    "                        u'div.sgc-toc-level-5', u'div.sgc-toc-level-6', u'div.sgc-toc-title', u'document',\n",
    "                        u'e-artnow', u'font-face', u'font-size', u'h1.sgc-4', u'h2.sgc-1', u'h2.sgc-3', \n",
    "                        u'inhaltsverzeichnis', u'line-height', u'margin-bottom', u'margin-left', u'margin:20',\n",
    "                        u' ', u'text-align', u'text-decoration'\n",
    "                       ))\n",
    "\n",
    "all_stopwords = default_stopwords | custom_stopwords\n",
    "\n",
    "def stick_the_books_together(book, number):\n",
    "    \"\"\" This function get all the different html books and put them to one book text/unicode string.\n",
    "    \n",
    "        input: \n",
    "        - book: text string\n",
    "        the path of the given book\n",
    "        \n",
    "        - number: integer\n",
    "        how many books are published\n",
    "        \n",
    "        \n",
    "        output:\n",
    "        result: text of all the books\n",
    "        all the books    \n",
    "    \"\"\"\n",
    "    all_raw_text = ''\n",
    "    \n",
    "    for i in range(number):\n",
    "        #print(i)\n",
    "        path = corpus_root + book[i]\n",
    "        html = open(path).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        raw = soup.get_text()\n",
    "        all_raw_text = all_raw_text + raw\n",
    "    \n",
    "    return(all_raw_text)\n",
    "\n",
    "\n",
    "def create_connection(database):\n",
    "    \"\"\" create a database connection to the SQLite database \n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(database)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None \n",
    "\n",
    "\n",
    "def create_table(conn, create_table_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "        param conn: Connection object\n",
    "        param create_table_sql: a CREATE TABLE statement\n",
    "        return:\"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "    except Error as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "def create_the_book_db():\n",
    "    \n",
    "    database = './db/5pk.db'\n",
    "    \n",
    "    sql_create_tbl_Authors = \"\"\" CREATE TABLE IF NOT EXISTS tbl_Authors (\n",
    "                                    Author_ID integer NOT NULL Primary Key,\n",
    "                                    Author_NAME text NOT NULL);\"\"\"\n",
    "    \n",
    "    sql_create_tbl_Books = \"\"\" CREATE TABLE IF NOT EXISTS tbl_Books (\n",
    "                                    Book_ID integer NOT NULL Primary Key,\n",
    "                                    Book_NAME text NOT NULL,\n",
    "                                    Author_ID integer NOT NULL,\n",
    "                                    Year integer NOT NULL,\n",
    "                                    FOREIGN KEY (Author_ID) REFERENCES\n",
    "                                    tbl_Authors(Author_ID));\"\"\"\n",
    "    \n",
    "    sql_create_tbl_Sentences = \"\"\" CREATE TABLE IF NOT EXISTS tbl_Sentences (\n",
    "                                    Sentence_ID integer Primary Key,\n",
    "                                    Book_ID integer NOT NULL,\n",
    "                                    Sentence TEXT NOT NULL,\n",
    "                                    FOREIGN KEY (Book_ID) REFERENCES\n",
    "                                    tbl_Books(Book_ID));\"\"\"\n",
    "\n",
    "    \n",
    "    sql_create_ind_Authors_Author_ID = \"\"\" CREATE INDEX ind_Authors_Author_ID\n",
    "                                            ON tbl_Authors(Author_ID);\"\"\"\n",
    "    \n",
    "    sql_create_ind_Books_Book_ID = \"\"\" CREATE INDEX ind_Books_Book_ID\n",
    "                                        ON tbl_Books(Book_ID);\"\"\"\n",
    "    \n",
    "    sql_create_ind_Sentences_Sentence_ID = \"\"\" CREATE INDEX ind_Sentences_Sentence_ID \n",
    "                                                ON tbl_Sentences(Sentence_ID);\"\"\"\n",
    "    \n",
    "    # Connecting to the database file\n",
    "    conn = create_connection('./db/5pk.db')\n",
    "\n",
    "    if conn is not None:\n",
    "        #create Authors table\n",
    "        create_table(conn, sql_create_tbl_Authors)\n",
    "        #create Books table\n",
    "        create_table(conn, sql_create_tbl_Books)\n",
    "        #create Sentences\n",
    "        create_table(conn, sql_create_tbl_Sentences)\n",
    "        \n",
    "        #create the Indexes\n",
    "        create_table(conn, sql_create_ind_Authors_Author_ID)\n",
    "        create_table(conn, sql_create_ind_Books_Book_ID)\n",
    "        create_table(conn, sql_create_ind_Sentences_Sentence_ID)\n",
    "    else:\n",
    "        print(\"ERROR! cannot create the database connection.\")\n",
    "\n",
    "\n",
    "def create_author(conn, author):\n",
    "    \"\"\"\n",
    "    Create a new Author\n",
    "    :param conn:\n",
    "    :param author:\n",
    "    :return: Author_ID\n",
    "    \"\"\"\n",
    "    sql = '''INSERT INTO tbl_Authors(Author_NAME, )'''\n",
    "        \n",
    "def create_book(conn, book):\n",
    "    \"\"\"\n",
    "    Create a new book into the tbl_Books\n",
    "    :param conn:\n",
    "    :param book:\n",
    "    :return: book id\n",
    "    \"\"\"\n",
    "    sql = '''INSERT INTO tbl_Books(Book_NAME, Author_ID, Year)\n",
    "            VALUES(?,?,?) '''\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, book)\n",
    "    \n",
    "    return cur.lastrowid\n",
    "\n",
    "\n",
    "def create_sentences(conn, sentence):\n",
    "    \"\"\"\n",
    "    Create a new Sentence\n",
    "    :param conn:\n",
    "    :param sentence:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sql = ''' INSERT INTO tbl_Sentences(Book_ID, Sentence)\n",
    "            Values(?,?) '''\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, sentence)\n",
    "    return cur.lastrowid\n",
    "        \n",
    "\n",
    "def select_all_sentences(conn):\n",
    "    \"\"\"\n",
    "    Query all rows in the tbl_Sentences table\n",
    "    :param conn: the connection object\n",
    "    :return: print every row\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM tbl_Sentences\")\n",
    "    \n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        print(row)\n",
    "        \n",
    "        \n",
    "def select_sentences_by_sentence_id(conn, Book_ID):\n",
    "    \"\"\"\n",
    "    Query sentence by ID\n",
    "    :param conn: the connection object\n",
    "    :param Book_ID: \n",
    "    :return: print every row\n",
    "    \"\"\"\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELCET * FROM tbl_Sentences WHERE Book_ID=?\", (Book_ID,))\n",
    "    \n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        print(row)\n",
    "    \n",
    "def fill_the_db_with_books(list_of_books):\n",
    "    db = './db/5pk.db'    \n",
    "    conn = create_connection(db)\n",
    "    conn.text_factory = str\n",
    "    #INSERT INTO tbl_Books(Book_NAME, Author_ID, Year)\n",
    "    df = pd.DataFrame(list_of_books, columns=['Book_NAME', 'Author_ID', 'Year'])\n",
    "    #put the book list into the db\n",
    "    df.to_sql(\"tbl_Books\", conn, if_exists=\"append\")\n",
    "    \n",
    "    #check if everything is really in the db table\n",
    "    test = pd.read_sql_query(\"select * from tbl_Books;\", conn)\n",
    "    return test\n",
    "\n",
    "def fill_the_db_with_sentence(df_of_sentences):\n",
    "    db = './db/5pk.db'\n",
    "    conn = create_connection(db)\n",
    "    conn.text_factory = str\n",
    "    #INSERT INTO tbl_Sentence(Sentence, Book_ID)\n",
    "    #df = pd.DataFrame(list_of_sentences, columns=['Sentence', 'Book_ID'])\n",
    "    df = df_of_sentences\n",
    "    #put the sentences from a book into the db\n",
    "    df.to_sql(\"tbl_Sentences\", conn, if_exists=\"append\")\n",
    "    \n",
    "    #check if everything is really in the db table\n",
    "    test = pd.read_sql_query(\"select * from tbl_Sentences;\", conn)\n",
    "    return test\n",
    "\n",
    "def fill_the_db_with_authors(list_of_authors):\n",
    "    db = './db/5pk.db'\n",
    "    conn = create_connection(db)\n",
    "    conn.text_factory = str\n",
    "    #INSERT INTO tbl_Authors(Author_NAME)\n",
    "    df = pd.DataFrame(list_of_authors, columns=['Author_NAME'])\n",
    "    #put the author list into the db Authors\n",
    "    df.to_sql(\"tbl_Authors\", conn, if_exists=\"append\")\n",
    "    \n",
    "    #check if everything is really in the db author\n",
    "    test = pd.read_sql_query(\"select * from tbl_Authors;\", conn)\n",
    "    return test\n",
    "\n",
    "# book_list for the tbl_Books\n",
    "# this is the first lis in december 2017\n",
    "book_list = [('Demetrius', 0, 1805),\n",
    "               ('Der versöhnte Menschenfeind', 0, 1790),\n",
    "               ('Die Braut von Messina', 0, 1803),\n",
    "               ('Die Huldigung der Künste', 0, 1804),\n",
    "               ('Die Jungfrau von Orleans', 0, 1801),\n",
    "               ('Die Räuber', 0, 1781),\n",
    "               ('Die Verschwörung des Fiesco zu Genua', 0, 1784),\n",
    "               ('Don Carlos', 0, 1787),\n",
    "               ('Kabale und Liebe', 0, 1783),\n",
    "               ('Maria Stuart', 0, 1800),\n",
    "               ('Semele', 0, 1782),\n",
    "               ('Wallenstein', 0, 1799),\n",
    "               ('Wilhelm Tell', 0, 1804)              \n",
    "              ]\n",
    "\n",
    "author_list = [('Friedrich Schiller')]\n",
    "\n",
    "\n",
    "\n",
    "#create the book DB in the beginning, only once\n",
    "#create_the_book_db()\n",
    "#fill_the_db_with_authors(author_list)\n",
    "#fill_the_db_with_books(book_list)\n",
    "\n",
    "\n",
    "def process_every_text_and_put_the_sentences_into_a_df(list_of_books):\n",
    "    \"\"\"\n",
    "    :param list_of_books: [(\"name of book\", number of books)]: \n",
    "    [(raw_book_1,1),(raw_book_2,2)]\n",
    "    \n",
    "    :param conn: connection to the Database\n",
    "    \n",
    "    1. the list of book has to processed with the stick_the_books_together function\n",
    "    2. this raw text get the number i from the book list and this is the Book_ID number for the tbl_Books\n",
    "    \"\"\"\n",
    "    \n",
    "    Book_ID = list_of_books[0][0]\n",
    "    print(Book_ID)\n",
    "\n",
    "#process_every_text_and_put_the_sentences_into_a_df(raw_books_schiller)\n",
    "\n",
    "def create_sentences_list(text):\n",
    "    s =  sent_tokenize(text)\n",
    "    #remove the \\n stuff\n",
    "    \n",
    "    return s\n",
    "\n",
    "#sentences = create_sentences_list(wallenstein_all_raw)\n",
    "\n",
    "\n",
    "#for i in sentences:\n",
    "#    print(i)\n",
    "\n",
    "#test = nltk.Text(sentences)\n",
    "#print(len(test))\n",
    "\n",
    "\"\"\"\n",
    "following code is taken from\n",
    "https://github.com/AlliedToasters/nlp/blob/master/4.4.2_Challenge_0.ipynb\n",
    "\"\"\"\n",
    "\n",
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\"\"\"    \n",
    "# Load and clean the data.\n",
    "wallenstein_all_raw = stick_the_books_together(raw_book_12, 21)\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "wallenstein = re.sub(r'Chapter \\d+', '', wallenstein_all_raw)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "wallenstein = text_cleaner(wallenstein)\n",
    "\n",
    "\n",
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "#persuasion_doc = nlp(persuasion)\n",
    "\n",
    "\n",
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "#ersuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents)# + persuasion_sents)\n",
    "sentences.head()\n",
    "\"\"\"\n",
    "\n",
    "def text_analysis(all_raw_text, start = int, end = int):\n",
    "    \"\"\" This function get all_raw_text - maybe from stick_the_books_together() - \n",
    "    and did some analysis to return some wordlists\n",
    "    \n",
    "    the start and end characters are her to sort some type out at the beginning and the end of the book\n",
    "    \n",
    "    input:\n",
    "    - all_raw_text: unicode\n",
    "    - start character: int\n",
    "    - end character: int    \n",
    "    \"\"\"\n",
    "    \n",
    "    raw = all_raw_text[start:]\n",
    "    tokens = nltk.word_tokenize(raw)\n",
    "    \n",
    "    text = nltk.Text(tokens)\n",
    "    \n",
    "    # Remove single-character tokens (mostly punctuation)\n",
    "    text = [word for word in text if len(word) > 1]\n",
    "    \n",
    "    # Remove numbers\n",
    "    words = [word for word in text if not word.isnumeric()]\n",
    "    \n",
    "    # lowercase all words (default_stopwords are lowercase too)\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in all_stopwords]\n",
    "    \n",
    "    # return the processed word list\n",
    "    return words\n",
    "\n",
    "#test = text_analysis(wallenstein_all_raw, 400 ,70)\n",
    "#test = sorted(set(test))\n",
    "#for i in test:\n",
    "#    print(i)\n",
    "\n",
    "\n",
    "#this could be a function to \n",
    "# first - stick the books together\n",
    "# second - create sentences\n",
    "# third - made a DataFrame\n",
    "# fourth - append another column (Book_ID)\n",
    "# result is a Sentence-DF ready for sql input\n",
    "\n",
    "def stick_the_books_create_sentences_create_df(Book_ID, book_files, number_of_books):\n",
    "    text = stick_the_books_together(book_files, number_of_books)\n",
    "    text = create_sentences_list(text)\n",
    "    \n",
    "    text = pd.DataFrame(text, columns = [\"Sentence\"])\n",
    "    text['Book_ID'] = Book_ID\n",
    "    return text\n",
    "\n",
    "\n",
    "def put_all_book_sentences_into_the_db():\n",
    "    Demetrius = stick_the_books_create_sentences_create_df(0, raw_book_1, 1)\n",
    "    DerversoehnteMenschenfeind = stick_the_books_create_sentences_create_df(1, raw_book_2, 2)\n",
    "    DieBrautvonMessina = stick_the_books_create_sentences_create_df(2, raw_book_3, 7)\n",
    "    DieHuldigungderKuenste = stick_the_books_create_sentences_create_df(3, raw_book_4, 1)\n",
    "    DieJungfrauvonOrleans = stick_the_books_create_sentences_create_df(4, raw_book_5, 10)\n",
    "    DieRaeuber = stick_the_books_create_sentences_create_df(5, raw_book_6, 9)\n",
    "    DieVerschwoerungdesFiescozuGenua = stick_the_books_create_sentences_create_df(6, raw_book_7, 13)\n",
    "    DonCarlos = stick_the_books_create_sentences_create_df(7, raw_book_8, 9)\n",
    "    KabaleundLiebe = stick_the_books_create_sentences_create_df(8, raw_book_9, 7)\n",
    "    MariaStuart = stick_the_books_create_sentences_create_df(9, raw_book_10, 7)\n",
    "    Semele = stick_the_books_create_sentences_create_df(10, raw_book_11, 3)\n",
    "    Wallenstein = stick_the_books_create_sentences_create_df(11, raw_book_12, 21)\n",
    "    WilhelmTell = stick_the_books_create_sentences_create_df(12, raw_book_13, 7)\n",
    "    \n",
    "    ## Fill the Dataframes into the DB\n",
    "    sentence_db = fill_the_db_with_sentence(Demetrius)\n",
    "    sentence_db = fill_the_db_with_sentence(DerversoehnteMenschenfeind)\n",
    "    sentence_db = fill_the_db_with_sentence(DieBrautvonMessina)\n",
    "    sentence_db = fill_the_db_with_sentence(DieHuldigungderKuenste)\n",
    "    sentence_db = fill_the_db_with_sentence(DieJungfrauvonOrleans)\n",
    "    sentence_db = fill_the_db_with_sentence(DieRaeuber)\n",
    "    sentence_db = fill_the_db_with_sentence(DieVerschwoerungdesFiescozuGenua)\n",
    "    sentence_db = fill_the_db_with_sentence(DonCarlos)\n",
    "    sentence_db = fill_the_db_with_sentence(KabaleundLiebe)\n",
    "    sentence_db = fill_the_db_with_sentence(MariaStuart)\n",
    "    sentence_db = fill_the_db_with_sentence(Semele)\n",
    "    sentence_db = fill_the_db_with_sentence(Wallenstein)\n",
    "    sentence_db = fill_the_db_with_sentence(WilhelmTell)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(sentence_db)\n",
    "\n",
    "#ut_all_book_sentences_into_the_db()\n",
    "\n",
    "def read_the_sentences_table():\n",
    "    db = './db/5pk.db'\n",
    "    conn = create_connection(db)\n",
    "    conn.text_factory = str\n",
    "    \n",
    "    #check if everything is really in the db table\n",
    "    return pd.read_sql_query(\"select * from tbl_Sentences;\", conn)\n",
    "\n",
    "read_the_sentences_table()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: nltk in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already up-to-date: six in /usr/local/lib/python3.5/dist-packages (from nltk)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Book_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>2898</td>\n",
       "      <td>Behüte Gott!</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34792</th>\n",
       "      <td>4695</td>\n",
       "      <td>Octavio.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23553</th>\n",
       "      <td>1367</td>\n",
       "      <td>Diese Frage verstehe ich nicht ganz.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>212</td>\n",
       "      <td>Er soll zufrieden sein.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13571</th>\n",
       "      <td>1933</td>\n",
       "      <td>Rede nicht, Bella!</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17825</th>\n",
       "      <td>1220</td>\n",
       "      <td>Don Carlos kommt im Gespräch mit einem Pagen d...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15536</th>\n",
       "      <td>3898</td>\n",
       "      <td>Wenn ich den Schlüssel zu meinem weiblichen He...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37617</th>\n",
       "      <td>7520</td>\n",
       "      <td>(Pause.)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28953</th>\n",
       "      <td>2844</td>\n",
       "      <td>Burleigh (hastig).</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27078</th>\n",
       "      <td>969</td>\n",
       "      <td>Wozu sie also töten?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>244</td>\n",
       "      <td>Fassen sie Herz liebe Furchtsame.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22950</th>\n",
       "      <td>764</td>\n",
       "      <td>– Es ist wahr, liebe Sophie – ich habe dem Für...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>3127</td>\n",
       "      <td>Ich genieße die Gesetze.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27302</th>\n",
       "      <td>1193</td>\n",
       "      <td>Wenn du’s getan hast, so verfluch ich dich,   ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12018</th>\n",
       "      <td>380</td>\n",
       "      <td>Holla!</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39655</th>\n",
       "      <td>1478</td>\n",
       "      <td>Ich fühle, dass es schleunig mit mir endet.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23327</th>\n",
       "      <td>1141</td>\n",
       "      <td>Was gibt’s denn?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32588</th>\n",
       "      <td>2491</td>\n",
       "      <td>Ich will denn doch gerathen haben, Vetter,    ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34052</th>\n",
       "      <td>3955</td>\n",
       "      <td>Begreift Ihr nun?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18263</th>\n",
       "      <td>1658</td>\n",
       "      <td>Prinzessin (sieht ihn erstaunt an).</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>469</td>\n",
       "      <td>Die Blüthe deutet auf die schöne Frucht.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37979</th>\n",
       "      <td>7882</td>\n",
       "      <td>Man hört in der Ferne zwei Thüren nacheinander...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>1474</td>\n",
       "      <td>Die Klage kommt zu spät – Hier schaffet Hilfe!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35665</th>\n",
       "      <td>5568</td>\n",
       "      <td>Mein Feldherr, wen erwartet Ihr?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>3124</td>\n",
       "      <td>– daß du ihn fast kennen solltest?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1346</td>\n",
       "      <td>Sieh!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>376</td>\n",
       "      <td>Hier ist nicht die Rede von den Gefühlen der M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>203</td>\n",
       "      <td>Wir haben uns in des Kampfes Wuth          Nic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>105</td>\n",
       "      <td>O schöner Fremdling!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13918</th>\n",
       "      <td>2280</td>\n",
       "      <td>Alle verneigen sich.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24416</th>\n",
       "      <td>2230</td>\n",
       "      <td>nein!</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27161</th>\n",
       "      <td>1052</td>\n",
       "      <td>Das Urteil kann nicht mehr vollzogen werden,  ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12730</th>\n",
       "      <td>1092</td>\n",
       "      <td>Springe hoch, Mädchen!</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550</th>\n",
       "      <td>2782</td>\n",
       "      <td>– Besinne dich recht, mein Sohn!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28558</th>\n",
       "      <td>2449</td>\n",
       "      <td>Beschwatzen konnte dich der Plauderer,        ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23699</th>\n",
       "      <td>1513</td>\n",
       "      <td>Das Porte-Epée ist an deiner Seite des Pranger...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34488</th>\n",
       "      <td>4391</td>\n",
       "      <td>Es war, als ob die Erd’ ihn eingeschluckt.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26980</th>\n",
       "      <td>871</td>\n",
       "      <td>Was wünscht mein Volk noch?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36108</th>\n",
       "      <td>6011</td>\n",
       "      <td>Mit leichter Schuld gehst du in diesen Streit,...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24812</th>\n",
       "      <td>2626</td>\n",
       "      <td>(Sophie geht ab, Lady macht einen Gang durch d...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39271</th>\n",
       "      <td>1094</td>\n",
       "      <td>Was gibt’s?</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31703</th>\n",
       "      <td>1606</td>\n",
       "      <td>Das Erste aber und Hauptsächlichste          B...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24704</th>\n",
       "      <td>2518</td>\n",
       "      <td>Ferdinand (zurücktretend).</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023</th>\n",
       "      <td>2255</td>\n",
       "      <td>Moor.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17669</th>\n",
       "      <td>1064</td>\n",
       "      <td>– Versöhnung, Vater!</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22541</th>\n",
       "      <td>355</td>\n",
       "      <td>– Man trennt uns!</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>257</td>\n",
       "      <td>Axinia fällt durch die Eifersucht der Marina.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>94</td>\n",
       "      <td>Angelika.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38783</th>\n",
       "      <td>606</td>\n",
       "      <td>Winkelriedzeigt nach dem See:          Ha seht!</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19464</th>\n",
       "      <td>2859</td>\n",
       "      <td>Sei’s, was es wolle!</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24436</th>\n",
       "      <td>2250</td>\n",
       "      <td>Wurm.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13010</th>\n",
       "      <td>1372</td>\n",
       "      <td>Sie erschrecken mich. Leonore.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25197</th>\n",
       "      <td>3011</td>\n",
       "      <td>»Du bist verrathen, Ferdinand!</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31734</th>\n",
       "      <td>1637</td>\n",
       "      <td>Zweiter Auftritt Inhaltsverzeichnis    Wallens...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>2180</td>\n",
       "      <td>O jammervolle Mutter!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15069</th>\n",
       "      <td>3431</td>\n",
       "      <td>Sacco (im Gespräch mit Verrina).</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496</th>\n",
       "      <td>2399</td>\n",
       "      <td>Ist er schon lange hier?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37896</th>\n",
       "      <td>7799</td>\n",
       "      <td>Es ist geschehn.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9222</th>\n",
       "      <td>2454</td>\n",
       "      <td>(Will sie fortreißen.)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>1082</td>\n",
       "      <td>Der frommen Pflicht wollt’ ich ihr Recht erzei...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40308 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                           Sentence  Book_ID\n",
       "32995   2898                                       Behüte Gott!       11\n",
       "34792   4695                                           Octavio.       11\n",
       "23553   1367               Diese Frage verstehe ich nicht ganz.        8\n",
       "11850    212                            Er soll zufrieden sein.        6\n",
       "13571   1933                                 Rede nicht, Bella!        6\n",
       "17825   1220  Don Carlos kommt im Gespräch mit einem Pagen d...        7\n",
       "15536   3898  Wenn ich den Schlüssel zu meinem weiblichen He...        6\n",
       "37617   7520                                           (Pause.)       11\n",
       "28953   2844                                 Burleigh (hastig).        9\n",
       "27078    969                               Wozu sie also töten?        9\n",
       "807      244                  Fassen sie Herz liebe Furchtsame.        1\n",
       "22950    764  – Es ist wahr, liebe Sophie – ich habe dem Für...        8\n",
       "19732   3127                           Ich genieße die Gesetze.        7\n",
       "27302   1193  Wenn du’s getan hast, so verfluch ich dich,   ...        9\n",
       "12018    380                                             Holla!        6\n",
       "39655   1478        Ich fühle, dass es schleunig mit mir endet.       12\n",
       "23327   1141                                   Was gibt’s denn?        8\n",
       "32588   2491  Ich will denn doch gerathen haben, Vetter,    ...       11\n",
       "34052   3955                                  Begreift Ihr nun?       11\n",
       "18263   1658                Prinzessin (sieht ihn erstaunt an).        7\n",
       "1731     469           Die Blüthe deutet auf die schöne Frucht.        2\n",
       "37979   7882  Man hört in der Ferne zwei Thüren nacheinander...       11\n",
       "2736    1474     Die Klage kommt zu spät – Hier schaffet Hilfe!        2\n",
       "35665   5568                   Mein Feldherr, wen erwartet Ihr?       11\n",
       "9892    3124                 – daß du ihn fast kennen solltest?        5\n",
       "4995    1346                                              Sieh!        4\n",
       "376      376  Hier ist nicht die Rede von den Gefühlen der M...        0\n",
       "1465     203  Wir haben uns in des Kampfes Wuth          Nic...        2\n",
       "3585     105                               O schöner Fremdling!        3\n",
       "13918   2280                               Alle verneigen sich.        6\n",
       "...      ...                                                ...      ...\n",
       "24416   2230                                              nein!        8\n",
       "27161   1052  Das Urteil kann nicht mehr vollzogen werden,  ...        9\n",
       "12730   1092                             Springe hoch, Mädchen!        6\n",
       "9550    2782                   – Besinne dich recht, mein Sohn!        5\n",
       "28558   2449  Beschwatzen konnte dich der Plauderer,        ...        9\n",
       "23699   1513  Das Porte-Epée ist an deiner Seite des Pranger...        8\n",
       "34488   4391         Es war, als ob die Erd’ ihn eingeschluckt.       11\n",
       "26980    871                        Was wünscht mein Volk noch?        9\n",
       "36108   6011  Mit leichter Schuld gehst du in diesen Streit,...       11\n",
       "24812   2626  (Sophie geht ab, Lady macht einen Gang durch d...        8\n",
       "39271   1094                                        Was gibt’s?       12\n",
       "31703   1606  Das Erste aber und Hauptsächlichste          B...       11\n",
       "24704   2518                         Ferdinand (zurücktretend).        8\n",
       "9023    2255                                              Moor.        5\n",
       "17669   1064                               – Versöhnung, Vater!        7\n",
       "22541    355                                  – Man trennt uns!        8\n",
       "257      257      Axinia fällt durch die Eifersucht der Marina.        0\n",
       "657       94                                          Angelika.        1\n",
       "38783    606    Winkelriedzeigt nach dem See:          Ha seht!       12\n",
       "19464   2859                               Sei’s, was es wolle!        7\n",
       "24436   2250                                              Wurm.        8\n",
       "13010   1372                     Sie erschrecken mich. Leonore.        6\n",
       "25197   3011                     »Du bist verrathen, Ferdinand!        8\n",
       "31734   1637  Zweiter Auftritt Inhaltsverzeichnis    Wallens...       11\n",
       "3442    2180                              O jammervolle Mutter!        2\n",
       "15069   3431                   Sacco (im Gespräch mit Verrina).        6\n",
       "32496   2399                           Ist er schon lange hier?       11\n",
       "37896   7799                                   Es ist geschehn.       11\n",
       "9222    2454                             (Will sie fortreißen.)        5\n",
       "2344    1082  Der frommen Pflicht wollt’ ich ihr Recht erzei...        2\n",
       "\n",
       "[40308 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "#!pip3 install -U nltk\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sqlite3 import Error\n",
    "\n",
    "#############################\n",
    "#\n",
    "# read the data\n",
    "#\n",
    "#############################\n",
    "\n",
    "def create_connection(database):\n",
    "    \"\"\" create a database connection to the SQLite database \n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(database)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None \n",
    "\n",
    "def read_the_shuffled_sentences_table():\n",
    "    db = './db/5pk.db'\n",
    "    conn = create_connection(db)\n",
    "    conn.text_factory = str\n",
    "    \n",
    "    #check if everything is really in the db table\n",
    "    return pd.read_sql_query(\"select * from tbl_Sentences;\", conn)\n",
    "\n",
    "\n",
    "def get_the_cleaned_sentences():\n",
    "    shuffle = read_the_shuffled_sentences_table()\n",
    "    \n",
    "    # frac = 1 means all the rows in random order\n",
    "    shuffle = shuffle.sample(frac=1)\n",
    "    shuffle.columns = shuffle.columns.str.strip()\n",
    "    shuffle.shape\n",
    "    shuffle.describe\n",
    "    \n",
    "    #make a copy not to change the original - dont need that here\n",
    "    #df = shuffle.copy()\n",
    "    \n",
    "    #replace some leading space\n",
    "    shuffle.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "    \n",
    "    #clean the \\r and \\n from sentences strings (replace it with whitespaces)\n",
    "    shuffle['Sentence'] = shuffle['Sentence'].map(lambda x: x.replace('\\r',' ').replace('\\n', ' '))\n",
    "    \n",
    "    return shuffle\n",
    "\n",
    "\n",
    "#df.describe\n",
    "cleaned_sentences = get_the_cleaned_sentences()\n",
    "cleaned_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### have to check the following\n",
    "\n",
    "\n",
    "#Download the POS Tagger first\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "#<ConllCorpusReader in u'/home/user/Dokumente/Github/5pk/txt_edit'>\n",
    "root = '.'\n",
    "fileid = 'tiger.16012013.conll09'\n",
    "columntypes = ['ignore', 'words', 'ignore', 'ignore', 'pos']\n",
    "corp = nltk.corpus.ConllCorpusReader(root, fileid, columntypes, encoding='utf8')\n",
    "\n",
    "\n",
    "#load the tiger corpus to train the pos tagger later\n",
    "#corp = nltk.corpus.ConllCorpusReader('.', 'tiger_release_aug07.corrected.16012013.conll09',\n",
    "#                                     ['ignore', 'words', 'ignore', 'ignore', 'pos'],\n",
    "#                                     encoding='utf-8')\n",
    "\"\"\"\n",
    "print(corp)\n",
    "print(type(corp))\n",
    "print(corp.tagged_sents())\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "# explicitly make list, then LazySequence will traverse all items\n",
    "#https://stackoverflow.com/questions/39622121/nltk-perceptron-tagger-typeerror-lazysubsequence-object-does-not-support-ite\n",
    "tagged_sentences = [corp.tagged_sents()]\n",
    "i = math.floor(len(tagged_sentences)*0.2)\n",
    "testing_sentences = tagged_sentences[0:int(i)]\n",
    "training_sentences = tagged_sentences[int(i):]\n",
    "\n",
    "perceptron_tagger = nltk.tag.perceptron.PerceptronTagger(load=False)\n",
    "print(\"testtesttest\")\n",
    "print(training_sentences)\n",
    "print(len(training_sentences))\n",
    "perceptron_tagger.train(training_sentences)\n",
    "\n",
    "print(type(perceptron_tagger))\n",
    "\"\"\"\n",
    "\"\"\"the solution:\n",
    " https://stackoverflow.com/questions/39622121/nltk-perceptron-tagger-typeerror-lazysubsequence-object-does-not-support-ite\n",
    "\n",
    "Solution\n",
    "\n",
    "To work around the error, just explicitly create a list of the sentences from the nltk.corpus.brown package then random can shuffle the data properly.\n",
    "\n",
    "<code>\n",
    "    import nltk,math\n",
    "     explicitly make list, then LazySequence will traverse all items\n",
    "    tagged_sentences = [sentence for sentence in nltk.corpus.brown.tagged_sents(categories='news',tagset='universal')]\n",
    "    i = math.floor(len(tagged_sentences)*0.2)\n",
    "    testing_sentences = tagged_sentences[0:i]\n",
    "    training_sentences = tagged_sentences[i:]\n",
    "    perceptron_tagger = nltk.tag.perceptron.PerceptronTagger(load=False)\n",
    "    perceptron_tagger.train(training_sentences)\n",
    "\n",
    "</code>\n",
    "no error, yea!\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# set a split size: use 90% for training, 10% for testing\n",
    "split_perc = 0.1\n",
    "split_size = int(len(tagged_sents) * split_perc)\n",
    "train_sents, test_sents = tagged_sents[split_size:], tagged_sents[:split_size]\n",
    "\n",
    "\"\"\"\n",
    "#do a pos tagging for the test text\n",
    "#test = nltk.pos_tag(test)\n",
    "#print(test)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for book in raw_books_schiller:\n",
    "    path = corpus_root + book[0]\n",
    "    html = open(path).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    raw = soup.get_text()\n",
    "    print(\"########### jetzt kommt der Type\")\n",
    "    print(type(raw))\n",
    "    raw = raw[237:]\n",
    "    tokens = nltk.word_tokenize(raw)\n",
    "    \n",
    "    text = nltk.Text(tokens)\n",
    "\n",
    "    # Remove single-character tokens (mostly punctuation)\n",
    "    text = [word for word in text if len(word) > 1]\n",
    "    \n",
    "    # Remove numbers\n",
    "    words = [word for word in text if not word.isnumeric()]\n",
    "    \n",
    "    # Lowercase all words (default_stopwords are lowercase too)\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in all_stopwords]\n",
    "    \n",
    "    # Calculate frequency distribution\n",
    "    fdist = nltk.FreqDist(words)\n",
    "    \n",
    "    # Output top 20 words\n",
    "    for word, frequency in fdist.most_common(20):\n",
    "        print(u'{};{}'.format(word, frequency))\n",
    "\n",
    "    \n",
    "#    fdist1 = FreqDist(words)\n",
    "#    fdist1.most_common(50)\n",
    "#    \n",
    "#    vocab = sorted(set(words))\n",
    "#    \n",
    "#    for word in vocab:\n",
    "#        print(word)\n",
    "\"\"\"   \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "i = 0\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    print(filename)\n",
    "    f = open(path + '/' + filename)\n",
    "    soup = BeautifulSoup(f.read(), \"html5lib\")\n",
    "    i += 1\n",
    "    for i in soup.findAll(u\"\\u2018\"):\n",
    "        if i.text == u\"\\2018\" or u\"\\2019\" in i.text:\n",
    "            i.string = \"'\"\n",
    "    for i in soup.findAll(u\"\\u2019\"):\n",
    "        if i.text == u\"\\2018\" or u\"\\2019\" in i.text:\n",
    "            i.string = \"'\"\n",
    "    g = soup.get_text().encode('utf-8')\n",
    "    print(g)\n",
    "    \n",
    "    \n",
    "#for file in glob.glob('*.html'):\n",
    " #   detect()\n",
    " \n",
    " \"\"\"\n",
    "\n",
    "\"\"\"for book in raw_books_schiller:\n",
    "    print(book)\n",
    "    pcr = PlaintextCorpusReader(corpus_root + book[0],'.*')\n",
    "    pcr.fileids()\n",
    "    print(wordlist)\n",
    "    #num_chars = len(wordlist)\n",
    "    test = gutenberg.raw(wordlist)\n",
    "    num_words = gutenberg.words(wordlist)\n",
    "    num_sents = gutenberg.sents(wordlist)\n",
    "\n",
    "\n",
    "for book in raw_books_schiller:\n",
    "    num_chars = len(gutenberg.raw(book))\n",
    "    num_words = len(gutenberg.words(book))\n",
    "    num_sents = len(gutenberg.sents(book))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
