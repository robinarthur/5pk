{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import os.path\n",
    "import glob\n",
    "from chardet.universaldetector import UniversalDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzip_easy(source_filename, dest_dir):\n",
    "    zip_ref = zipfile.ZipFile(source_filename, 'r')\n",
    "    zip_ref.extractall(dest_dir)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_txt(dir):\n",
    "    for path in glob.glob('/' + dir + '/*.txt'):\n",
    "        with open(path) as markup:\n",
    "            soup = BeautifulSoup(markup.read(),\"html5lib\" )\n",
    "        with open(\"strip_\" + path, \"w\") as f:\n",
    "            f.write(soup.get_text().encode('ISO-8859-2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect(file):\n",
    "    \"\"\"Function to detect the right charset in the textfile\"\"\"\n",
    "    detector = UniversalDetector()\n",
    "    for filename in glob.glob(file):\n",
    "        print(filename.ljust(60),detector.reset())\n",
    "        for line in file(filename, 'rb'):\n",
    "            detector.feed(line)\n",
    "            if detector.done:\n",
    "                break\n",
    "    \n",
    "    detector.close()\n",
    "    print(detector.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./txt/schiller.txt                                          ', None)\n",
      "{'confidence': 0.818998663630605, 'encoding': 'ISO-8859-2'}\n",
      "53778\n",
      "(53778L, 'all_Lines:')\n",
      "('./txt/goethe1.txt                                           ', None)\n",
      "{'confidence': 0.8284653609588577, 'encoding': 'ISO-8859-2'}\n",
      "17848\n",
      "(71626L, 'all_Lines:')\n",
      "('./txt/goethe2.txt                                           ', None)\n",
      "{'confidence': 0.99, 'encoding': 'utf-8'}\n",
      "7744\n",
      "(79370L, 'all_Lines:')\n"
     ]
    }
   ],
   "source": [
    "schiller = './txt/schiller.txt'\n",
    "goethe1 = './txt/goethe1.txt'\n",
    "goethe2 = './txt/goethe2.txt'\n",
    "\n",
    "authors = [schiller, goethe1, goethe2]\n",
    "all_lines = 0\n",
    "for txt in authors:\n",
    "    open(txt)\n",
    "    detect(txt)\n",
    "    f=open(txt,'r')\n",
    "    lines=0L\n",
    "    for line in f.xreadlines():\n",
    "        lines+=1L\n",
    "    print(lines)\n",
    "    all_lines = lines + all_lines\n",
    "    print(all_lines, \"all_Lines:\")\n",
    "    f.close()\n",
    "    #soup = BeautifulSoup(f.read(),\"html5lib\" )\n",
    "    #g = soup.get_text().encode('ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epub_goethe1 = \"./epubs/goethe1.epub\"\n",
    "epub_goethe2 = \"./epubs/goethe2.epub\"\n",
    "epub_schiller = \"./epubs/schiller.epub\"\n",
    "\n",
    "dir_goethe1 = \"./unzip/goethe1\"\n",
    "dir_goethe2 = \"./unzip/goethe2\"\n",
    "dir_schiller = \"./unzip/schiller\"\n",
    "\n",
    "unzip_easy(epub_goethe1, dir_goethe1)\n",
    "unzip_easy(epub_goethe2, dir_goethe2)\n",
    "unzip_easy(epub_schiller, dir_schiller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bookwire_advertisement5\n"
     ]
    }
   ],
   "source": [
    "# look for the content.opf file and look for the all <itemref idref= lines and store them into a list.\n",
    "schilleropf = \"./unzip/schiller/OEBPS/content.opf\"\n",
    "\n",
    "file = open(schilleropf, \"r\")\n",
    "soup = BeautifulSoup(file.read(),\"html5lib\")\n",
    "\n",
    "#get the names of all html files of all books\n",
    "idref_schiller2 = soup.find_all('itemref')\n",
    "#print(idref_schiller2)\n",
    "\n",
    "#dateien die ich nicht brauche\n",
    "#items_delete = ['titlepage.html', 'frontpage.html', 'TOC.html', 'bookwire_advertisment1',\n",
    "#                'bookwire_advertisment2','bookwire_advertisment3','bookwire_advertisment4',\n",
    "#                'bookwire_advertisment5',]\n",
    "\n",
    "idref_schiller2 = line.get('idref')\n",
    "print(idref_schiller2)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
